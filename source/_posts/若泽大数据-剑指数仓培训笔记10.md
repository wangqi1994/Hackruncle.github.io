---
title: "数仓培训第十天"
catalog: true
toc_nav_num: true
date: 2020-05-11 12:00:00
subtitle: "主从架构、读写流程、副本放置策略"
article_type: 0 # 0 原创，1 转载
tags:
- [Hadoop]
- [HDFS]
categories:
- [Hadoop]
- [HDFS]
updateDate: 2020-05-11 12:00:00
top: 0  #置顶
---


### 1.HDFS主从架构
80%以上的大数据是主从结构-主管理从干活
![HDFS主从架构官网图](/img/Hadoop/HDFS主从架构.png)
角色:
#### namenode  名称节点 nn    
a.文件名称
b.文件的目录结构
c.文件的属性 权限 创建时间 副本数
```bash
[hadoop@hadoop001 hadoop]$ hdfs dfs -ls /wordcount2/input
20/05/12 08:56:23 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... 
using builtin-java classes where applicable
Found 2 items
-rw-r--r--   1 hadoop supergroup         29 2020-05-11 16:14 /wordcount2/input/1.log
-rw-r--r--   1 hadoop supergroup         47 2020-05-11 16:14 /wordcount2/input/2.log
[hadoop@hadoop001 hadoop]$ 
```
d.一个文件被对应切割哪些数据块、副本数的块、数据块对应分布在哪些节点上
blockmap 块映射，nn节点不会持久化存储这种映射关系
是通过集群的启动和运行时，dn定期发送blockreport给nn，然后nn就在内存中动态维护这种映射关系

作用:
管理文件系统的命名空间  其实就是维护文件系统树的文件和文件夹
这些形式是以两种文件来永久的保存在本地磁盘的
镜像文件 fsimage
编辑日志文件 editlogs
```bash
[hadoop@hadoop001 current]$ pwd
/home/hadoop/tmp/dfs/name/current
[hadoop@hadoop001 current]$ ll
total 198880
-rw-rw-r--. 1 hadoop hadoop 191753254 May 11 16:08 edits_0000000000000000003-0000000000001047334
-rw-rw-r--. 1 hadoop hadoop  10755011 May 11 17:09 edits_0000000000001047335-0000000000001114386
-rw-rw-r--. 1 hadoop hadoop       158 May 11 18:09 edits_0000000000001114387-0000000000001114390
-rw-rw-r--. 1 hadoop hadoop        42 May 11 19:09 edits_0000000000001114391-0000000000001114392
-rw-rw-r--. 1 hadoop hadoop        42 May 11 20:09 edits_0000000000001114393-0000000000001114394
-rw-rw-r--. 1 hadoop hadoop        42 May 11 21:09 edits_0000000000001114395-0000000000001114396
-rw-rw-r--. 1 hadoop hadoop        42 May 11 22:09 edits_0000000000001114397-0000000000001114398
-rw-rw-r--. 1 hadoop hadoop        42 May 11 23:09 edits_0000000000001114399-0000000000001114400
-rw-rw-r--. 1 hadoop hadoop        42 May 12 00:09 edits_0000000000001114401-0000000000001114402
-rw-rw-r--. 1 hadoop hadoop        42 May 12 01:09 edits_0000000000001114403-0000000000001114404
-rw-rw-r--. 1 hadoop hadoop        42 May 12 02:09 edits_0000000000001114405-0000000000001114406
-rw-rw-r--. 1 hadoop hadoop        42 May 12 03:09 edits_0000000000001114407-0000000000001114408
-rw-rw-r--. 1 hadoop hadoop        42 May 12 04:09 edits_0000000000001114409-0000000000001114410
-rw-rw-r--. 1 hadoop hadoop        42 May 12 05:09 edits_0000000000001114411-0000000000001114412
-rw-rw-r--. 1 hadoop hadoop        42 May 12 06:09 edits_0000000000001114413-0000000000001114414
-rw-rw-r--. 1 hadoop hadoop        42 May 12 07:09 edits_0000000000001114415-0000000000001114416
-rw-rw-r--. 1 hadoop hadoop        42 May 12 08:09 edits_0000000000001114417-0000000000001114418
-rw-rw-r--. 1 hadoop hadoop        42 May 12 09:09 edits_0000000000001114419-0000000000001114420
-rw-rw-r--. 1 hadoop hadoop   1048576 May 12 09:09 edits_inprogress_0000000000001114421
-rw-rw-r--. 1 hadoop hadoop      2299 May 12 08:09 fsimage_0000000000001114418
-rw-rw-r--. 1 hadoop hadoop        62 May 12 08:09 fsimage_0000000000001114418.md5
-rw-rw-r--. 1 hadoop hadoop      2299 May 12 09:09 fsimage_0000000000001114420
-rw-rw-r--. 1 hadoop hadoop        62 May 12 09:09 fsimage_0000000000001114420.md5
-rw-rw-r--. 1 hadoop hadoop         8 May 12 09:09 seen_txid
-rw-rw-r--. 1 hadoop hadoop       205 May 11 15:32 VERSION
```

#### secondary namenode  第二名称节点  snn
a.将fsimage editlog定期拿过来合并 备份 推送
```bash
[hadoop@hadoop001 current]$ pwd
/home/hadoop/tmp/dfs/namesecondary/current
[hadoop@hadoop001 current]$ ll
total 197848
-rw-rw-r--. 1 hadoop hadoop 191753254 May 11 16:08 edits_0000000000000000003-0000000000001047334
-rw-rw-r--. 1 hadoop hadoop  10755011 May 11 17:09 edits_0000000000001047335-0000000000001114386
-rw-rw-r--. 1 hadoop hadoop       158 May 11 18:09 edits_0000000000001114387-0000000000001114390
-rw-rw-r--. 1 hadoop hadoop        42 May 11 19:09 edits_0000000000001114391-0000000000001114392
-rw-rw-r--. 1 hadoop hadoop        42 May 11 20:09 edits_0000000000001114393-0000000000001114394
-rw-rw-r--. 1 hadoop hadoop        42 May 11 21:09 edits_0000000000001114395-0000000000001114396
-rw-rw-r--. 1 hadoop hadoop        42 May 11 22:09 edits_0000000000001114397-0000000000001114398
-rw-rw-r--. 1 hadoop hadoop        42 May 11 23:09 edits_0000000000001114399-0000000000001114400
-rw-rw-r--. 1 hadoop hadoop        42 May 12 00:09 edits_0000000000001114401-0000000000001114402
-rw-rw-r--. 1 hadoop hadoop        42 May 12 01:09 edits_0000000000001114403-0000000000001114404
-rw-rw-r--. 1 hadoop hadoop        42 May 12 02:09 edits_0000000000001114405-0000000000001114406
-rw-rw-r--. 1 hadoop hadoop        42 May 12 03:09 edits_0000000000001114407-0000000000001114408
-rw-rw-r--. 1 hadoop hadoop        42 May 12 04:09 edits_0000000000001114409-0000000000001114410
-rw-rw-r--. 1 hadoop hadoop        42 May 12 05:09 edits_0000000000001114411-0000000000001114412
-rw-rw-r--. 1 hadoop hadoop        42 May 12 06:09 edits_0000000000001114413-0000000000001114414
-rw-rw-r--. 1 hadoop hadoop        42 May 12 07:09 edits_0000000000001114415-0000000000001114416
-rw-rw-r--. 1 hadoop hadoop        42 May 12 08:09 edits_0000000000001114417-0000000000001114418
-rw-rw-r--. 1 hadoop hadoop        42 May 12 09:09 edits_0000000000001114419-0000000000001114420
-rw-rw-r--. 1 hadoop hadoop      2299 May 12 08:09 fsimage_0000000000001114418
-rw-rw-r--. 1 hadoop hadoop        62 May 12 08:09 fsimage_0000000000001114418.md5
-rw-rw-r--. 1 hadoop hadoop      2299 May 12 09:09 fsimage_0000000000001114420
-rw-rw-r--. 1 hadoop hadoop        62 May 12 09:09 fsimage_0000000000001114420.md5
-rw-rw-r--. 1 hadoop hadoop       205 May 12 09:09 VERSION
```
snn将老大的  edits_0000000000001114419-0000000000001114420进行合并操作（检查点操作，checkpoint），合并为fsimage_0000000000001114420
 将这个文件推送给老大，那么新的数据写读的记录就存放在edits_inprogress_0000000000001114421日志文件
文件是变化的内容不断追加

dfs.namenode.checkpoint.period  3600s 按时间备份
dfs.namenode.checkpoint.txns    1000000 如果数据读写量大，超过限制，会立即备份

为了解决单点故障，nn只有一个对外的，后来新增一个snn，1小时的备份
虽然能够减轻单点故障带来的丢失风险，但是在生产上还是不允许使用snn
例如
11:00  snn 备份
11:30  数据一直写到这  突然nn节点 磁盘故障 无法恢复
拿snn的最新的一个fsimage文件恢复，那么只能恢复 11点的数据

**在生产上是 不用snn，是启动另外一个NN进程(实时备份，实时准备替换nn，变为活动的nn)叫做HDFS HA**


#### datanode  数据节点  dn
a.存储数据块和数据块的校验和

作用:
a.每隔3s发送心跳给nn,告诉nn说明dn还活着
dfs.heartbeat.interval  3s

b.每隔一定的时间发生一次blockreport
dfs.blockreport.intervalMsec   21600000ms=6小时
dfs.datanode.directoryscan.interval  21600s=6小时
```bash
[hadoop@hadoop001 subdir99]$ pwd
/home/hadoop/tmp/dfs/data/current/BP-512886540-192.168.111.131-1589182330952/current/finalized/subdir0/subdir99
```
补充: 
[HDFS Block损坏恢复方法](https://ruozedata.github.io/2019/06/06/%E7%94%9F%E4%BA%A7HDFS%20Block%E6%8D%9F%E5%9D%8F%E6%81%A2%E5%A4%8D%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5(%E5%90%AB%E6%80%9D%E8%80%83%E9%A2%98)/)
如果生产上检测到块损坏,集群会自己修复
手动修复不一定成功，看人品
手动回复需要集群上有3个副本

**注意：hdfs不要以为时间的参数单位是一样的，需要查看命令帮助确认**

### 2.HDFS写流程 

[HDFS写流程](https://wangqi1994.github.io/2020/05/11/HDFS写流程/)


### 3.HDFS读流程

[HDFS读流程](https://wangqi1994.github.io/2020/05/11/HDFS读流程/)




### 4.HDFS副本放置策略 

[HDFS副本放置策略](https://wangqi1994.github.io/2020/05/11/HDFS副本放置策略/)




