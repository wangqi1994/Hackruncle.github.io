---
title: "数仓培训第十天"
catalog: true
toc_nav_num: true
date: 2020-05-11 12:00:00
subtitle: "主从架构、读写流程、副本放置策略"
article_type: 0 # 0 原创，1 转载
tags:
- [Hadoop]
- [HDFS]
categories:
- [Hadoop]
- [HDFS]
updateDate: 2020-05-11 12:00:00
top: 0  #置顶
---


1.HDFS
主从架构
角色:
namenode  名称节点 nn    
a.文件名称
b.文件的目录结构
c.文件的属性 权限 创建时间 副本数
[hadoop@ruozedata001 ~]$ hdfs dfs -ls  /wordcount2/input/
20/05/10 20:12:38 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Found 2 items
-rw-r--r--   1 hadoop supergroup         35 2020-05-09 21:34 /wordcount2/input/1.log
-rw-r--r--   1 hadoop supergroup         29 2020-05-09 21:34 /wordcount2/input/2.log
[hadoop@ruozedata001 ~]$ 
d.一个文件被对应切割哪些数据块 副本数的块  9块===》数据块对应分布在哪些节点上
blockmap 块映射  当然nn节点是不会持久化存储这种映射关系
是通过集群的启动和运行时，dn定期发送blockreport给nn，然后nn就在内存中动态维护这种映射关系

作用:
管理文件系统的命名空间  其实就是维护文件系统树的文件和文件夹
这些形式是以两种文件来永久的保存在本地磁盘的
镜像文件 fsimage
编辑日志文件 editlogs

[hadoop@ruozedata001 current]$ pwd
/home/hadoop/tmp/dfs/name/current
[hadoop@ruozedata001 current]$ ll
edits_0000000000000000375-0000000000000000376
edits_0000000000000000377-0000000000000000378
edits_0000000000000000379-0000000000000000380
edits_0000000000000000381-0000000000000000382
edits_0000000000000000383-0000000000000000384
edits_0000000000000000385-0000000000000000386
edits_inprogress_0000000000000000387
fsimage_0000000000000000384
fsimage_0000000000000000384.md5
fsimage_0000000000000000386
fsimage_0000000000000000386.md5


secondary namenode  第二名称节点  snn
a.fsimage editlog定期拿过来合并 备份 推送
[hadoop@ruozedata001 current]$ pwd
/home/hadoop/tmp/dfs/namesecondary/current
[hadoop@ruozedata001 current]$ 
edits_0000000000000000377-0000000000000000378
edits_0000000000000000379-0000000000000000380
edits_0000000000000000381-0000000000000000382
edits_0000000000000000383-0000000000000000384
edits_0000000000000000385-0000000000000000386
fsimage_0000000000000000384
fsimage_0000000000000000384.md5
fsimage_0000000000000000386
fsimage_0000000000000000386.md5
             
	     fsimage_0000000000000000384
snn将老大的  edits_0000000000000000385-0000000000000000386   ==》检查点动作 checkpoint  合并为
             
	     fsimage_0000000000000000386 将这个386文件推送给老大，
	     那么新的数据写读的记录就存放在edits_inprogress_0000000000000000387 日志文件  是变化的 追加


	    dfs.namenode.checkpoint.period  3600s 
	    dfs.namenode.checkpoint.txns    1000000 

	 为了解决单点故障，nn只有一个对外的，后来新增一个snn，1小时的备份
	 虽然能够减轻单点故障带来的丢失风险，但是在生产上还是不允许使用snn

	 11:00  snn 备份

	 11:30  数据一直写到这  突然nn节点 磁盘故障 无法恢复
	 拿snn的最新的一个fsimage文件恢复，那么只能恢复 11点的数据

	 在生产上是 不用snn，是启动另外一个NN进程(实时备份，实时准备替换nn，变为活动的nn)
         叫做HDFS HA



             

datanode  数据节点  dn
a.存储数据块和数据块的校验和

作用:
a.每隔3s发送心跳给nn,告诉 我还活着
dfs.heartbeat.interval  3s

b.每隔一定的时间发生一次blockreport
dfs.blockreport.intervalMsec   21600000ms=6小时
dfs.datanode.directoryscan.interval  21600s=6小时

[hadoop@ruozedata001 subdir0]$ pwd
/home/hadoop/tmp/dfs/data/current/BP-672629417-192.168.0.3-1588775739687/current/finalized/subdir0/subdir0
[hadoop@ruozedata001 subdir0]$ 

补充: https://ruozedata.github.io/2019/06/06/%E7%94%9F%E4%BA%A7HDFS%20Block%E6%8D%9F%E5%9D%8F%E6%81%A2%E5%A4%8D%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5(%E5%90%AB%E6%80%9D%E8%80%83%E9%A2%98)/


2.HDFS写流程  面试
[hadoop@ruozedata001 ~]$ echo 'ruozedata' >1.log
[hadoop@ruozedata001 ~]$ 
[hadoop@ruozedata001 ~]$ hdfs dfs -put 1.log  /
20/05/10 21:19:54 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[hadoop@ruozedata001 ~]$ 

对用户操作是无感知的 
1.HDFS Client调用FileSystem.create(filePath)方法，去和NN进行【RPC】通信！
NN 会去check这个路径的文件是否已经存在，是否有权限能够创建这个文件！
假如都ok，就去创建一个新的文件，但是这时还没写数据，是不关联任何的block。
nn根据上传的文件大小，根据块大小+副本数参数，
计算要上传多少块和块存储在DN的位置。最终将这些信息返回给客户端，
为【FSDataOutputStream】对象

2.Client调用【FSDataOutputStream】对象的write方法，
将第一个块的第一个副本数写第一个DN节点，
写完去第二个副本写DN2；写完去第三个副本写DN3。
当第三个副本写完，就返回一个ack packet确定包给DN2节点，
当DN2节点收到这个ack packet确定包加上自己也是写完了，就返回一个ack packet确定包给
第一个DN1节点，当DN1节点收到这个ack packet确定包加上自己也是写完了，
将ack packet确定包返回给【FSDataOutputStream】对象，就标识第一个块的三个副本写完。，
其他块以此类推！

3.当所有的块全部写完， client调用 【FSDataOutputStream】对象的close方法，
关闭输出流。再次调用FileSystem.complete方法，告诉nn文件写成功！

伪分布式 1台dn  副本数参数必然是设置1
dn挂了，肯定不能写入


生产分布式 3台dn  副本数参数必然是设置3
dn挂了，肯定不能写入


生产分布式 >3台dn  副本数参数必然是设置3
dn挂了，能写入


存活的alive dn节点数>=副本数 就能写成功


3.HDFS读流程 面试
[hadoop@ruozedata001 ~]$ hdfs dfs -cat  /1.log
20/05/10 21:53:19 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
ruozedata
[hadoop@ruozedata001 ~]$ 
对用户操作是无感知的 

1.Client调用FileSystem的open(filePath),
与NN进行RPC通信，返回该文件的部分或者全部的block列表
也就是返回【FSDataInputStream】对象

2.Client调用【FSDataInputStream】对象的read方法
去与第一个块的最近的DN进行读取，读取完成后，会check，假如ok，就关闭与DN通信。
假如读取失败，会记录DN+block信息，下次就不会从这个节点读取。那么就从第二个节点读取。

然后去与第二个块的最近的DN进行读取，以此类推。

假如当block列表全部读取完成，文件还没读取结束，就调用FileSystem从nn获取下一批次的block列表。

3.Client调用【FSDataInputStream】对象close方法，关闭输入流。




4.HDFS副本放置策略 不光光面试，生产也需要
机架 rack1 5   rack2 5


生产上读写操作 尽量选择 某个DN节点
第一个副本：
放置在上传的DN节点；
假如是非DN节点，就随机挑选一个磁盘不太慢，cpu不太忙的节点；

第二个副本：
放置在第一个副本不同的机架上的某个DN节点。

第三个副本:
与第二个副本相同机架的不同节点上。

如果副本数设置更多，就随机放。


作业：
1.hdfs yarn部署启动  博客
2.jps pid整理      博客
3.读写流程  副本数 博客


